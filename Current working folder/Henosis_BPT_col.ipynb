{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bc6f83-9f30-4334-ba71-9de52bfa66a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from openpyxl import load_workbook, Workbook\n",
    "import openpyxl\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef7b246-5b69-4935-bdeb-8586de5c3029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the O drive location where we'll save our files\n",
    "path = r\"\\\\fpcl01\\public\\OFWSHARE\\PR24\\231002 - Business Plan Submissions\\1_Files as submitted by companies\\Core\"\n",
    "path2 = r\"O:\\OFWSHARE\\PR24\\231113 - Business Plan Submissions\\2_Files after Panacea\\Core\\Amended files\"\n",
    "path3 = r\"O:\\OFWSHARE\\PR24\\231113 - Business Plan Submissions\\3_Files error fixing WORKING\\Core\"\n",
    "\n",
    "#os.chdir(path2)  # Change the directory to the O drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25482e00-203c-4c9b-be34-4b58b781cb0c",
   "metadata": {},
   "source": [
    "### Unhide all sheets and define the source extracter (this should run only once) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79477ca3-ad99-4017-bf74-3f550a387e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 42s\n",
      "Wall time: 14min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#for file in glob.glob(r\"*.xls*\"):  \n",
    "for file in glob.glob(\"ANH03 PR24 Data Tables ANH resubmission 10.11.2023_Amended.xlsx\"): \n",
    "    hidden_sheet_names = ['fOut_OUT', 'fOut_OUT8', 'fOut_RR', 'fOut_CW', 'fOut_CW_MAN', 'fOut_CWW', 'fOut_CWW_MAN', 'fOut_RES', 'fOut_BIO', 'fOut_RET', 'fOut_RET_MAN', 'fOut_DS', 'fOut_DS_MAN', 'fOut_LS', 'fOut_LS_MAN', 'fOut_SUP', 'fOut_SUP_MAN', 'fOut_SUM', 'fOut_PD', 'fOut_PD_MAN', 'fOut_APR']\n",
    "    wb = load_workbook(file)\n",
    "    \n",
    "    # Iterate through each hidden sheet and unhide it\n",
    "    for sheet_name in hidden_sheet_names:\n",
    "        ws = wb[sheet_name]\n",
    "        ws.sheet_state = \"visible\"\n",
    "    # Save the changes\n",
    "    wb.save(file)\n",
    "    wb.close()    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58788e29-79f7-4a65-a7d3-b0059678da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cell_source(foutput):\n",
    "    sources = [] #Create a list to store our data in\n",
    "    for row in foutput.iter_rows(min_row=4, min_col=2, max_col=2):\n",
    "        for cell in row:\n",
    "            formula = str(cell.value)\n",
    "            if formula.startswith(\"=\") and formula.count(\"'\") >= 2:\n",
    "                #Check if the formula starts with a single quote and contains at least two single quotes\n",
    "                start_index = formula.find(\"'\") + 1  # Find the first single quote\n",
    "                end_index = formula.find(\"'\", start_index)  # Find the second single quote\n",
    "                referenced_sheet = formula[start_index:end_index] \n",
    "            elif formula.startswith(\"=\") and formula.count(\"!\")>0 and formula.count(\"(\")>0:\n",
    "                start_index = formula.find(\"(\") + 1 \n",
    "                end_index = formula.find(\"!\", start_index)  \n",
    "                referenced_sheet = formula[start_index:end_index].replace(\"'\", \"\")\n",
    "            else:\n",
    "                # If the formula doesn't follow the expected pattern, set referenced_sheet to None\n",
    "                referenced_sheet = formula.replace(\"=\", \"\")\n",
    "            sources.append(referenced_sheet)\n",
    "    source_series = sources\n",
    "    return source_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20bc478-b2c0-456a-a6bd-6fcb166ac233",
   "metadata": {},
   "source": [
    "### Main Function that will create the Aggragated All.xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f3d801-36d6-47d4-8eea-063d7288bf61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 60 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Create an empty list to store data\n",
    "data = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#  find sheet names containing \"fOut\" in a case-insensitive manner \n",
    "sheet_name_pattern = re.compile(r'fOut', re.I)\n",
    "\n",
    "source = []\n",
    "\n",
    "#for file in glob.glob(r\"*.xls*\"): \n",
    "for file in glob.glob(\"ANH03 PR24 Data Tables ANH resubmission 10.11.2023_Amended.xlsx\"): \n",
    "    workbook = openpyxl.load_workbook(file, data_only=True)\n",
    "    formula_workbook = openpyxl.load_workbook(file, data_only=False)\n",
    "    acronym = file[:3]\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        if sheet_name_pattern.search(sheet_name):\n",
    "            worksheet = workbook[sheet_name]\n",
    "            source = source + find_cell_source(formula_workbook[sheet_name])\n",
    "            # Create a list to store headers\n",
    "            headers = []\n",
    "            for row_index, row in enumerate(worksheet.iter_rows(values_only=True), start=1):\n",
    "                if row_index == 2:  # Process the second row as headers\n",
    "                    headers = [cell for cell in row]\n",
    "                elif row_index != 1 and row_index != 3:  # Skip the first and third row\n",
    "                    # Create a dictionary to store row data\n",
    "                    row_data = {'Acronym': acronym, 'Sheet_name': sheet_name}\n",
    "                    for header, cell in zip(headers, row):\n",
    "                        row_data[header] = cell\n",
    "                    # Explicitly set 'Acronym' to an file[:3] if it's None\n",
    "                    if row_data['Acronym'] is None:\n",
    "                        row_data['Acronym'] = file[:3]\n",
    "                    data.append(row_data)\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "bpt_series = pd.Series(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c7ad92-f917-47c3-b987-c199c1ebf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BPT\"] = bpt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fe01d3-9d9c-488e-944b-273dab9d9123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reorder and select columns\n",
    "selected_columns = [\"Acronym\", \"Reference\", \"Sheet_name\",\"BPT\", \"Item description\", \"Unit\", \"Model\", 'Constant', # Reorder the years columns\n",
    "         \"2011-12\", \"2012-13\", \"2013-14\", \"2014-15\", \"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\", \"2019-20\", \"2020-21\", \"2021-22\", \"2022-23\", \"2023-24\", \"2024-25\", \"2025-26\", \"2026-27\", \"2027-28\", \"2028-29\", \"2029-30\", \"2030-31\", \"2031-32\", \"2032-33\", \"2033-34\", \"2034-35\",\n",
    "         \"2020-25\", \"2025-30\", \"2030-35\", \"2035-40\", \"2040-45\", \"2045-50\",\n",
    "         '2039-40', '2044-45', '2025-55', '2049-50']\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119c1f4-7eb9-4d4e-983e-d95edb27aa34",
   "metadata": {},
   "source": [
    "### Aggragated file with All F_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b93b88-62b7-434e-8fca-2351e4cff876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results to excel\n",
    "df.to_excel(r\"C:\\Users\\Jennifer.Tossell\\OneDrive - OFWAT\\Documents\\Coding\\All.xlsx\", sheet_name=\"F_Outputs\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52644fff-b74c-4958-bad8-f633a314d489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the results to excel\n",
    "#df.to_excel(r\"O:\\OFWSHARE\\PR24\\231113 - Business Plan Submissions\\3_Files error fixing WORKING\\Core\\Aggregated outputs\\Jen's Aggregated outputs\\All_BPT_Extracts.xlsx\", sheet_name=\"F_Outputs\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3447953-64d6-43f3-b488-de9982135d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acronym - Here write the acronym you want to replace\n",
    "#new_acronym - Here write what you want to replace it with\n",
    "\n",
    "def acronym_fix(acronym, new_acronym, cleaned_df):\n",
    "    \n",
    "    #First replace the Acronym column with the correction\n",
    "    temp1 = cleaned_df['Acronym'].replace(acronym, new_acronym)\n",
    "    cleaned_df['Acronym'] = temp1\n",
    "    \n",
    "    #Now replace boncodes containing this acronym with the correction\n",
    "    temp2 = cleaned_df['Reference'].str.replace(acronym, new_acronym, regex=True)\n",
    "    cleaned_df['Reference'] = temp2\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c01554-388f-4f75-a706-3e2745d48144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(df):\n",
    "    # List of column names where you want to apply data cleaning\n",
    "    columns_to_replace = [\"2011-12\", \"2012-13\", \"2013-14\", \"2014-15\", \"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\", \"2019-20\", \"2020-21\", \"2021-22\", \"2022-23\", \"2023-24\", \"2024-25\", \"2025-26\", \"2026-27\", \"2027-28\", \"2028-29\", \"2029-30\", \"2030-31\", \"2031-32\", \"2032-33\", \"2033-34\", \"2034-35\",\n",
    "         \"2020-25\", \"2025-30\", \"2030-35\", \"2035-40\", \"2040-45\", \"2045-50\",\n",
    "         '2039-40', '2044-45', '2025-55', '2049-50']\n",
    "    problem_cells = ['NR', 'not found', 'No historic data', 'NA', 'N/A', 'n/a', ']', 'N/a']\n",
    "\n",
    "    # Data Cleaning\n",
    "    for column in columns_to_replace:\n",
    "        df[column] = df[column].replace('#DIV/0!', '', regex=True)\n",
    "        df[column] = df[column].replace({True: 1, False: 0})\n",
    "        \n",
    "    # Replace values in problem_cells with an empty string\n",
    "    df.replace(problem_cells, '', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4dd641-04da-4524-abcd-9157f16e05fd",
   "metadata": {},
   "source": [
    "### Data Cleaning on Glob All.xlsx (replace #DIV/0!, True: 1, False: 0, 'NR', 'not found', 'No historic data', 'NA', 'N/A', 'n/a', ']', 'N/a' to empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7142bbc-22c1-4967-ac99-68522a2f59e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 19s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#Data Cleaning###########################\n",
    "cleaned_df = acronym_fix('UUW','NWT',df)\n",
    "cleaned_df=cleaning_data(cleaned_df)\n",
    "\n",
    "# Export the results to excel\n",
    "cleaned_df.to_excel(r\"O:\\OFWSHARE\\PR24\\231113 - Business Plan Submissions\\2_Files after Panacea\\Core\\Aggregated outputs\\\\\" + \"All_data_clean.xlsx\", sheet_name=\"F_Outputs\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa8226-ba34-4fd4-88aa-fdd15a5b72ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
